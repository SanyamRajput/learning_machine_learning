{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "private_outputs": true,
   "authorship_tag": "ABX9TyP+0tHKVZEOnNnAIG86KVwJ"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# CLASSIFICATION\n",
   "metadata": {
    "id": "0mHCn_JPyjth"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ],
   "metadata": {
    "id": "C8TfRVzoDGBy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### dataset:\n",
    "Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "Donated by: P. Savicky Institute of Computer Science, AS of CR Czech Republic savicky '@' cs.cas.cz"
   ],
   "metadata": {
    "id": "COPPpnWHl5Sc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "cols = [\"fLength\", \"fWidth\", \"fSize\", \"fConc\", \"fConc1\", \"fAsym\", \"fM3Long\", \"fM3Trans\", \"fAlpha\", \"fDist\", \"class\"] #name for the columns of the\n",
    "df = pd.read_csv(\"magic04.data\", names=cols)\n",
    "df.head()"
   ],
   "metadata": {
    "id": "T0PWY0-rhdn9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "each entity in the dataset is a data point .\n",
    "\n",
    "each data point has a label (the cols) and a class"
   ],
   "metadata": {
    "id": "egl93X_ppABZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#df[\"class\"].unique()\n",
    "#data labled g (gamma particles) -> 1 and h (hadron particals) -> 0\n",
    "df[\"class\"] = (df[\"class\"] == \"g\").astype(int)"
   ],
   "metadata": {
    "id": "Nejvd3VFi4z2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#using ONE HOT ENCODING\n",
    "df.head()"
   ],
   "metadata": {
    "id": "nH7wh8XQoJH1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "now ploting the data in the form fo histogram (lables)\n",
    "\n"
   ],
   "metadata": {
    "id": "jXXJVTff4yd-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for label in cols[:-1]:\n",
    "  plt.hist(df[df[\"class\"]==1][label], color='blue', label='gamma', alpha=0.7, density=True)\n",
    "  plt.hist(df[df[\"class\"]==0][label], color='red', label='hadron', alpha=0.7, density=True)\n",
    "  plt.title(label)\n",
    "  plt.ylabel(\"Probability\")\n",
    "  plt.xlabel(label)\n",
    "  plt.legend()\n",
    "  plt.show()"
   ],
   "metadata": {
    "id": "TikSdo5e4-FR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "###Train, validation, test datasets\n"
   ],
   "metadata": {
    "id": "C89GU6rSAC6i"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train, vaild, test = np.split(df.sample(frac=1), [int(0.6*len(df)), int(0.8*len(df))])"
   ],
   "metadata": {
    "id": "Yw7b2DkZBNJH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def scale_dataset(dataframe, oversample=False):\n",
    "  x = dataframe[dataframe.columns[:-1]].values\n",
    "  y = dataframe[dataframe.columns[-1]].values\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  X = scaler.fit_transform(x)\n",
    "\n",
    "  if oversample:\n",
    "    ros = RandomOverSampler()\n",
    "    X, y = ros.fit_resample(X, y)\n",
    "\n",
    "  data = np.hstack((X, np.reshape(y, (-1, 1))))\n",
    "\n",
    "  return data, X, y\n"
   ],
   "metadata": {
    "id": "D4Nrou9UCzSy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "items inthe datasets train\n",
    "\n"
   ],
   "metadata": {
    "id": "SEwtnvOAfKqb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(train[train[\"class\"]==1])) #gammas\n",
    "print(len(train[train[\"class\"]==0])) #hadrons"
   ],
   "metadata": {
    "id": "BqXi79O2fVCP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train, X_train, y_train = scale_dataset(train, oversample=True)\n",
    "vaild, X_vaild, y_vaild = scale_dataset(vaild, oversample=False)\n",
    "test, X_test, y_test = scale_dataset(test, oversample=False)"
   ],
   "metadata": {
    "id": "hlLBMTYxbyMk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNN model\n",
    "-the new point will take the label of the majority around it.\n"
   ],
   "metadata": {
    "id": "ovB_qYeRms2D"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report"
   ],
   "metadata": {
    "id": "_CurFQsrmv2j"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)"
   ],
   "metadata": {
    "id": "1XuYvjdFm9DB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred = knn_model.predict(X_test)"
   ],
   "metadata": {
    "id": "KemDgJDOq4c9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "id": "zm6V4Bt9rFgs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "###naive bayes\n",
    "-uses condational probability"
   ],
   "metadata": {
    "id": "7lQ_W00g7d0_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ],
   "metadata": {
    "id": "zn7vxVVZrlRp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model = nb_model.fit(X_train, y_train)"
   ],
   "metadata": {
    "id": "hhtAHLRq8az3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred = nb_model.predict(X_train)\n",
    "print(classification_report(y_train, y_pred))"
   ],
   "metadata": {
    "id": "n10uLbHw8wFa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "###logistic regression\n",
    "-map the given data in terms of sigmoidal function"
   ],
   "metadata": {
    "id": "Mt5l-U06Dxnx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ],
   "metadata": {
    "id": "M7nYxP_H9J9m"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "lg_model = LogisticRegression()\n",
    "lg_model = lg_model.fit(X_train, y_train)"
   ],
   "metadata": {
    "id": "VUE38D6pEFV0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred = lg_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "id": "ukanq6W7EeAz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "###Support Vector Machine\n",
    "-dividing the data into two parts using a hyperplane\n",
    "\n"
   ],
   "metadata": {
    "id": "ZnyIyJJzxQvw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC"
   ],
   "metadata": {
    "id": "EUB3D7RIFEPT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "svm_model = SVC()\n",
    "svm_model = svm_model.fit(X_train, y_train)"
   ],
   "metadata": {
    "id": "9XKx12_p4SH-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred = svm_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "id": "K6n1rR7y4hII"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# neural network\n",
    "-tnsorflow\n",
    "\n"
   ],
   "metadata": {
    "id": "mOrHMSRsPbxI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n"
   ],
   "metadata": {
    "id": "B8YHI7r-4pH8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "-loss function and accuracy plot"
   ],
   "metadata": {
    "id": "5QzvPLCKUsJO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_history(history):\n",
    "  fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,4))\n",
    "  ax1.plot(history.history[\"loss\"], label = 'accuracy')\n",
    "  ax1.plot(history.history['val_loss'], label = 'val_loss')\n",
    "  ax1.set_xlabel('epoch')\n",
    "  ax1.set_ylabel('binary crossentropy')\n",
    "  ax1.grid(True)\n",
    "\n",
    "  ax2.plot(history.history[\"accuracy\"], label = 'accuracy')\n",
    "  ax2.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "  ax2.set_xlabel('epoch')\n",
    "  ax2.set_ylabel('accuracy')\n",
    "  ax2.grid(True)\n",
    "\n",
    "  plt.show()"
   ],
   "metadata": {
    "id": "l8TqTiMkPq1Q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "-neural network model defining"
   ],
   "metadata": {
    "id": "revX0PXLU2RZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def train_model(X_train, y_train, num_nodes, dropout_prob, lr, batch_size, epochs):\n",
    "  nn_model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(num_nodes, activation='relu', input_shape=(10,)),\n",
    "      tf.keras.layers.Dropout(dropout_prob),\n",
    "      tf.keras.layers.Dense(num_nodes, activation='relu'),\n",
    "      tf.keras.layers.Dropout(dropout_prob),\n",
    "      tf.keras.layers.Dense(1, activation= 'sigmoid')\n",
    "  ])\n",
    "\n",
    "  nn_model.compile(optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics = ['accuracy'])\n",
    "  history = nn_model.fit(\n",
    "      X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0\n",
    "  )\n",
    "\n",
    "  return nn_model, history"
   ],
   "metadata": {
    "id": "euAEZgZwSXav"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "least_val_loss = float('inf')\n",
    "least_loss_model = None\n",
    "epochs = 100\n",
    "for num_nodes in [16,32,64]:\n",
    "  for dropout_prob in [0,0.2]:\n",
    "    for lr in [0.01, 0.005, 0.001]:\n",
    "      for batch_size in [32,64,128]:\n",
    "        print(f\"{num_nodes} nodes, dropout {dropout_prob}, lr {lr}, batch size {batch_size} \")\n",
    "        model, history = train_model(X_train=X_train, y_train=y_train, num_nodes=num_nodes, dropout_prob=dropout_prob, lr=lr, batch_size=batch_size, epochs=epochs )\n",
    "        plot_history(history)\n",
    "        val_loss = model.evaluate(X_vaild, y_vaild)[0]\n",
    "        if val_loss < least_val_loss:\n",
    "          least_val_loss = val_loss\n",
    "          least_loss_model = model"
   ],
   "metadata": {
    "id": "fkGHVtfNSdAw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred = least_loss_model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int).reshape(-1,)"
   ],
   "metadata": {
    "id": "rNYnOMDsZID9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "id": "kr1o5PFzZwAP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "_j4XONUOZyuf"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
